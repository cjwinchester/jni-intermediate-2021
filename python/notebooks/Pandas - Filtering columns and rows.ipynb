{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering columns and rows in pandas\n",
    "\n",
    "This notebook has a little more detail on selecting and filtering data in pandas. We'll use the MLB salary data as an example -- a CSV lives at `'../data/mlb.csv'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the read_csv() method to create a data frame\n",
    "df = pd.read_csv('../data/mlb.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the `head()` method to check out what we've got\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting one column of data\n",
    "\n",
    "You can select a column of data using dot notation `.` or bracket notation: `[]`.\n",
    "\n",
    "If you want to select a single column of data and the column name doesn't have spaces, you can use a period (\"dot notation\"). You could also pass the name of the column as a string inside square brackets (\"bracket notation\"); if your column names have spaces (avoid this if you can), you _must_ use bracket notation.\n",
    "\n",
    "Let's say we wanted to select the `TEAM` column. We could do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.TEAM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... or we could do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['TEAM']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Either works. And: Not a huge deal, but it's generally good practice to pick one and stay consistent, at least within the same script."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting multiple columns of data\n",
    "\n",
    "To select multiple columns of data, you use _bracket notation_ -- but instead of putting a single column name inside the brackets, you hand it a _list_ of column names.\n",
    "\n",
    "ðŸ‘‰ For a refresher on _lists_, [check out this notebook](http://localhost:8888/notebooks/appendix/Python%20data%20types%20and%20basic%20syntax.ipynb#Lists).\n",
    "\n",
    "Let's select the `NAME` and `TEAM` columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_and_team = df[['NAME', 'TEAM']]\n",
    "\n",
    "name_and_team.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lots of square brackets happening there! An alternative: You could assign the list of column names that you want to select to its own variable to make things a little clearer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_of_interest = ['TEAM', 'NAME']\n",
    "df[cols_of_interest].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A good rule of thumb: If you can do anything in your script to make things clearer, or more explicit, for other people reading your code (including your future self), do it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering rows of data\n",
    "\n",
    "You can also filter your data set to keep just the rows that meet your filtering condition(s) -- like using the filter dropdowns in Excel or a `WHERE` clause in SQL.\n",
    "\n",
    "Let's say you wanted to filter our MLB data to include just the Los Angeles Dodgers.\n",
    "\n",
    "First, we need to make sure that we understand how \"Los Angeles Dodgers\" is represented in the data. We can use the `unique()` method to get a unique list of values in the `TEAM` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.TEAM.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we want to find all the records in our data where the value in the `TEAM` column is \"LAD\". The equivalent SQL would be:\n",
    "\n",
    "```SQL\n",
    "SELECT *\n",
    "FROM mlb\n",
    "WHERE TEAM = \"LAD\"\n",
    "```\n",
    "\n",
    "With pandas, the basic syntax is to pass your filtering condition to the data frame in square brackets `[]`. We'll use Python's `==` [comparison operator](https://docs.python.org/3/reference/expressions.html#value-comparisons) to test for equality. Typically, you'd also want to \"save\" the results of your filtering by assigning the result to a variable that you can access later:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lad = df[df['TEAM'] == 'LAD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lad.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can do numerical comparisons -- let's get just the players who make $1 million or more:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "millionaires = df[df['SALARY'] >= 1000000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "millionaires.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, if it makes your script clearer, more readable, you can break your filter up into multiple pieces -- \"save\" the filtering condition under a new variable and _then_ hand that off to the data frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_a_2_millionaire = df['SALARY'] >= 2000000\n",
    "two_millionaires = df[is_a_2_millionaire]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "two_millionaires.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering against multiple matches\n",
    "You can use the [`isin()`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.isin.html) method to test a value against multiple matches -- just hand it your list of values to check against.\n",
    "\n",
    "Let's say we wanted to return all of the players for the Texas Rangers and Houston Astros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx = df[df['TEAM'].isin(['TEX', 'HOU'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx.TEAM.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOT filtering\n",
    "\n",
    "You can filter for data that do _not_ meet some criteria by prepending a tilde `~`.\n",
    "\n",
    "Let's filter for all players that _aren't_ in Texas. It'll be the same as the filtering statement above but with a tilde at the beginning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_tx = df[~df['TEAM'].isin(['TEX', 'HOU'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_tx.TEAM.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering on multiple criteria\n",
    "\n",
    "You can filter your data on multiple criteria. A few gotchas:\n",
    "- Don't use Python's `and` and `or` operators to chain the statements -- [pandas wants you to use `&` and `|`](https://pandas.pydata.org/pandas-docs/version/0.22/indexing.html#boolean-indexing)\n",
    "- Don't forget to use parentheses to group your statements\n",
    "\n",
    "Let's filter for all catchers who make the league minimum of $535,000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catchers_lm = df[(df['POS'] == 'C') & (df['SALARY'] == 535000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catchers_lm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much of the time, though, it's clearer to just break up your filtering into multiple statements, like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catchers = df[df['POS'] == 'C']\n",
    "catchers_lm = catchers[catchers['SALARY'] == 535000]\n",
    "\n",
    "catchers_lm"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
